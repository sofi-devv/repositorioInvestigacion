{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso y Metodología de Extracción de Comentarios\n",
    "\n",
    "Se busca extraer los links de los videos de los canales seleccionados en el dataset de **noticias** hasta que estos sumen, como mínimo, 250,000 comentarios en su conjunto, para aquellos que tienen una categoría distinta a \"Internacional\".\n",
    "\n",
    "## Criterio de Selección\n",
    "\n",
    "- **Palabras Claves**: Las palabras claves estarán contenidas en el dataset 'claves' (nombre del presidente, país del presidente) junto con la palabra \"presidente\".\n",
    "- **Número mínimo de comentarios:** El minimo de número de comentarios del video son 100 para que este sea considerado en la lista.\n",
    "- **Dataset 'claves'**: Este dataset tiene 2 columnas: una llamada \"País\" y otra \"Nombre del Presidente\". Para esta búsqueda solo se usará la columna \"Nombre del Presidente\".\n",
    "- **Periodo de Tiempo**: Los videos deben ser del último año.\n",
    "- **Filtrado Inicial**: Inicialmente, solo se buscará filtrar los videos que contengan los criterios de las palabras y conocer cuántos comentarios tienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias=  pd.read_excel('canales_noticias_con_id.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claves = pd.read_excel(\"data/tables/presidentes2024.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claves.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de la Función `get_video_details`\n",
    "\n",
    "#### Propósito\n",
    "Obtiene detalles de un video en YouTube utilizando la API de YouTube Data.\n",
    "\n",
    "#### Parámetro\n",
    "- `video_id`: El identificador único del video en YouTube.\n",
    "\n",
    "#### Funcionamiento\n",
    "1. Llama a la API de YouTube para obtener datos del video (`snippet`, `contentDetails`, `statistics`).\n",
    "2. Verifica si la respuesta contiene elementos y selecciona el primer video.\n",
    "3. Extrae y almacena los siguientes detalles:\n",
    "   - Título del video\n",
    "   - Descripción\n",
    "   - Fecha de publicación\n",
    "   - Duración\n",
    "   - Número de comentarios\n",
    "4. Crea un diccionario con estos detalles y lo devuelve. Si no hay datos, devuelve `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(video_id):\n",
    "    video_response = youtube.videos().list(\n",
    "        part=\"snippet,contentDetails,statistics\", # se recolecta la información de los metadatos del video y las estadísticas\n",
    "        id=video_id\n",
    "    ).execute()\n",
    "    \n",
    "    if \"items\" in video_response and len(video_response[\"items\"]) > 0: # si se encontró el video en youtube se extrae la información\n",
    "        video = video_response[\"items\"][0] # se extrae la información del video en cuestión \n",
    "        title = video[\"snippet\"][\"title\"] # se extrae el título del video\n",
    "        description = video[\"snippet\"][\"description\"] # se extrae la descripción del video\n",
    "        published_at = video[\"snippet\"][\"publishedAt\"] # se extrae la fecha de publicación del video\n",
    "        duration = video[\"contentDetails\"][\"duration\"] # se extrae la duración del video\n",
    "        comment_count = int(video[\"statistics\"].get(\"commentCount\", 0)) # se extrae el número de comentarios del video \n",
    "        video_data = { # se crea un diccionario con la información del video\n",
    "            \"Nombre del Video\": title,\n",
    "            \"Link del Video\": f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "            \"Numero de Comentarios\": comment_count,\n",
    "            \"Duración del Video\": duration,\n",
    "            \"Fecha del Video\": published_at\n",
    "        }\n",
    "        return video_data\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar las columnas 'País' y 'Nombre del Presidente' de 'claves' y añadir la palabra \"presidente\"\n",
    "claves['Query'] = claves['País'] + \" \" + claves['Nombre del Presidente'] + \" presidente\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de datos de enero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la fecha actual y establecer las fechas de inicio y fin para el mes de enero del año actual\n",
    "current_date = datetime.now()\n",
    "january_first = datetime(current_date.year, 1, 1).isoformat(\"T\") + \"Z\"\n",
    "january_end = datetime(current_date.year, 1, 31, 23, 59, 59).isoformat(\"T\") + \"Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para buscar videos en un canal con palabras clave específicas y dentro del rango de fechas especificado\n",
    "\n",
    "#### Propósito\n",
    "Busca videos en un canal de YouTube que coincidan con palabras clave específicas y un rango de fechas determinado.\n",
    "\n",
    "#### Parámetros\n",
    "- `channel_id`: El identificador único del canal de YouTube.\n",
    "- `query`: Las palabras clave para buscar videos.\n",
    "- `published_after`: La fecha de inicio del rango (en formato ISO 8601).\n",
    "- `published_before`: La fecha de fin del rango (en formato ISO 8601).\n",
    "- `max_results` (opcional): El número máximo de resultados a devolver (por defecto, 5).\n",
    "\n",
    "#### Funcionamiento\n",
    "1. **Llamada a la API de Búsqueda de YouTube**:\n",
    "   - Realiza una búsqueda en el canal especificado utilizando las palabras clave y el rango de fechas.\n",
    "   - Ordena los resultados por cantidad de visualizaciones y limita el número de resultados según `max_results`.\n",
    "\n",
    "2. **Recopilación de Resultados**:\n",
    "   - Itera sobre los resultados de búsqueda.\n",
    "   - Para cada video encontrado, obtiene detalles específicos utilizando la función `get_video_details`.\n",
    "\n",
    "3. **Filtrado y Almacenamiento de Videos**:\n",
    "   - Filtra los videos que tienen más de 100 comentarios.\n",
    "   - Almacena los datos de los videos que cumplen con este criterio en una lista.\n",
    "\n",
    "4. **Devolución de Resultados**:\n",
    "   - Devuelve la lista de videos que cumplen con los criterios de búsqueda y tienen más de 100 comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para buscar videos en un canal con palabras clave específicas y dentro del rango de fechas especificado\n",
    "def search_videos(channel_id, query, published_after, published_before, max_results=5):\n",
    "    search_response = youtube.search().list(\n",
    "        channelId=channel_id, # se busca en el canal con el ID proporcionado\n",
    "        q=query, # se busca la palabra clave en los títulos y descripciones\n",
    "        type=\"video\", # se buscan solo videos\n",
    "        part=\"id,snippet\", # se recolectan los metadatos del video y la información de la búsqueda\n",
    "        maxResults=max_results, # se obtienen 5 resultados como máximo por búsqueda dado el límite de cuotas\n",
    "        order='viewCount', # se ordenan los resultados por vistas\n",
    "        publishedAfter=published_after, # se obtienen solo los videos publicados después de la fecha especificada\n",
    "        publishedBefore=published_before   # se obtienen solo los videos publicados antes de la fecha especificada\n",
    "    ).execute()\n",
    "    \n",
    "    videos = []\n",
    "    for search_result in search_response.get(\"items\", []): # se recorren los resultados de la búsqueda\n",
    "        video_id = search_result[\"id\"][\"videoId\"] # se extrae el ID del video\n",
    "        video_data = get_video_details(video_id) # se obtiene la información detallada del video\n",
    "        if video_data and video_data[\"Numero de Comentarios\"] > 100: # si se encontró información y el video tiene más de 100 comentarios\n",
    "            videos.append(video_data) # se añade la información del video a la lista de videos\n",
    "    return videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para buscar videos en múltiples canales y guardarlos en un archivo CSV\n",
    "\n",
    "#### Propósito\n",
    "Busca videos en múltiples canales de YouTube utilizando palabras clave específicas dentro de un rango de fechas y guarda los resultados en un archivo CSV.\n",
    "\n",
    "#### Parámetros\n",
    "- `noticias`: DataFrame que contiene información sobre los noticieros, incluidas las categorías, nombres y IDs de los canales.\n",
    "- `claves`: DataFrame que contiene las palabras clave para la búsqueda, incluyendo los nombres de los presidentes y sus países.\n",
    "- `january_first`: Fecha de inicio del rango (1 de enero en formato ISO 8601).\n",
    "- `january_end`: Fecha de fin del rango (31 de enero en formato ISO 8601).\n",
    "\n",
    "#### Funcionamiento\n",
    "1. **Inicialización**:\n",
    "   - Crea una lista vacía `videos` para almacenar los datos de los videos encontrados.\n",
    "\n",
    "2. **Iteración sobre los canales**:\n",
    "   - Recorre cada fila del DataFrame `noticias`.\n",
    "   - Extrae el `ChannelID`, `Categoría` y `Nombre del noticiero`.\n",
    "\n",
    "3. **Verificación y Búsqueda de Videos**:\n",
    "   - Si el `ChannelID` no es nulo, itera sobre cada fila del DataFrame `claves`.\n",
    "   - Extrae la `Query` (consulta de búsqueda) y el `País`.\n",
    "   - Llama a la función `search_videos` con el `channel_id`, `query`, `january_first` y `january_end`.\n",
    "\n",
    "4. **Procesamiento de Resultados de Búsqueda**:\n",
    "   - Para cada resultado de búsqueda, si el video tiene más de 100 comentarios, se agregan datos adicionales:\n",
    "     - `Nombre del noticiero`\n",
    "     - `Query` utilizada\n",
    "     - `País` (se ajusta dependiendo de si la categoría es \"Internacional\")\n",
    "\n",
    "5. **Almacenamiento de Resultados**:\n",
    "   - Los detalles de los videos encontrados se agregan a la lista `videos`.\n",
    "\n",
    "6. **Guardado en CSV**:\n",
    "   - Se convierte la lista `videos` en un DataFrame `df_videos`.\n",
    "   - Se guarda el DataFrame en un archivo CSV (`./videos-per-month/enero.csv`).\n",
    "\n",
    "7. **Actualización de `claves`**:\n",
    "   - Se concatena `País` y `Nombre del Presidente` en `claves` para formar la `Query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar videos y guardar en CSV\n",
    "videos = []\n",
    "for _, row in noticias.iterrows(): # Recorrer cada fila de 'noticias'\n",
    "    channel_id = row['ChannelID'] # Obtener el ID del canal de la fila actual\n",
    "    categoria = row['Categoría'] # Obtener la categoría del noticiero\n",
    "    nombre_noticiero = row['Nombre del noticiero'] # Obtener el nombre del noticiero\n",
    "    \n",
    "    if pd.notnull(channel_id): # Si el ID del canal no es nulo\n",
    "        for _, clave_row in claves.iterrows(): # Recorrer cada fila de 'claves'\n",
    "            query = clave_row['Query'] # Obtener la consulta de la fila actual\n",
    "            country = clave_row['País'] # Obtener el país de la fila actual\n",
    "            search_results = search_videos(channel_id, query, january_first, january_end) # Buscar videos en el canal con la consulta y fechas especificadas\n",
    "            for video in search_results: # Recorrer cada video encontrado en los resultados de la búsqueda\n",
    "                if video:\n",
    "                    video[\"Nombre del noticiero\"] = nombre_noticiero # Agregar el nombre del noticiero a los datos del video\n",
    "                    video[\"Query\"] = query  # Agregar la consulta a los datos del video\n",
    "                    if categoria == \"Internacional\": # Si la categoría del noticiero es internacional\n",
    "                        video[\"País\"] = f\"Internacional + {country}\"\n",
    "                    else:\n",
    "                        video[\"País\"] = categoria + \" \" + country # Agregar el país a los datos del video\n",
    "                    videos.append(video)\n",
    "\n",
    "# Crear DataFrame y guardar en CSV\n",
    "df_videos = pd.DataFrame(videos)\n",
    "df_videos.to_csv(\"./videos-per-month/enero.csv\", index=False)\n",
    "\n",
    "print(\"Videos data saved to ./videos-per-month/enero.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos[\"Numero de Comentarios\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de datos de febrero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now()\n",
    "february_first = datetime(current_date.year, 2, 1).isoformat(\"T\") + \"Z\"\n",
    "february_end = datetime(current_date.year, 2, 29, 23, 59, 59).isoformat(\"T\") + \"Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se vuelve a correr la consulta de el mes de enero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar videos y guardar en CSV\n",
    "videos = []\n",
    "for _, row in noticias.iterrows():\n",
    "    channel_id = row['ChannelID']\n",
    "    categoria = row['Categoría']\n",
    "    nombre_noticiero = row['Nombre del noticiero']\n",
    "    \n",
    "    if pd.notnull(channel_id):\n",
    "        for _, clave_row in claves.iterrows():\n",
    "            query = clave_row['Query']\n",
    "            country = clave_row['País']\n",
    "            search_results = search_videos(channel_id, query, february_first, february_end)\n",
    "            for video in search_results:\n",
    "                if video:\n",
    "                    video[\"Nombre del noticiero\"] = nombre_noticiero\n",
    "                    video[\"Query\"] = query  # Agregar la consulta a los datos del video\n",
    "                    if categoria == \"Internacional\":\n",
    "                        video[\"País\"] = f\"Internacional + {country}\"\n",
    "                    else:\n",
    "                        video[\"País\"] = categoria\n",
    "                    videos.append(video)\n",
    "\n",
    "# Crear DataFrame y guardar en CSV\n",
    "df_videos = pd.DataFrame(videos)\n",
    "df_videos.to_csv(\"./videos-per-month/febrero.csv\", index=False)\n",
    "\n",
    "print(\"Videos data saved to ./videos-per-month/febrero.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos[\"Numero de Comentarios\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de datos de Marzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now()\n",
    "march_first = datetime(current_date.year, 3, 1).isoformat(\"T\") + \"Z\"\n",
    "march_end = datetime(current_date.year, 3, 31, 23, 59, 59).isoformat(\"T\") + \"Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se vuelve a correr la consulta de el mes de enero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "for _, row in noticias.iterrows():\n",
    "    channel_id = row['ChannelID']\n",
    "    categoria = row['Categoría']\n",
    "    nombre_noticiero = row['Nombre del noticiero']\n",
    "    \n",
    "    if pd.notnull(channel_id):\n",
    "        for _, clave_row in claves.iterrows():\n",
    "            query = clave_row['Query']\n",
    "            country = clave_row['País']\n",
    "            search_results = search_videos(channel_id, query, march_first, march_end)\n",
    "            for video in search_results:\n",
    "                if video:\n",
    "                    video[\"Nombre del noticiero\"] = nombre_noticiero\n",
    "                    video[\"Query\"] = query  # Agregar la consulta a los datos del video\n",
    "                    if categoria == \"Internacional\":\n",
    "                        video[\"País\"] = f\"Internacional + {country}\"\n",
    "                    else:\n",
    "                        video[\"País\"] = categoria\n",
    "                    videos.append(video)\n",
    "\n",
    "# Crear DataFrame y guardar en CSV\n",
    "df_videos = pd.DataFrame(videos)\n",
    "df_videos.to_csv(\"./videos-per-month/marzo.csv\", index=False)\n",
    "\n",
    "print(\"Videos data saved to ./videos-per-month/marzo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos[\"Numero de Comentarios\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de datos de Abril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now()\n",
    "april_first = datetime(current_date.year, 4, 1).isoformat(\"T\") + \"Z\"\n",
    "april_end = datetime(current_date.year, 4, 30, 23, 59, 59).isoformat(\"T\") + \"Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se vuelve a correr la consulta de el mes de enero con las fechas modificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "for _, row in noticias.iterrows():\n",
    "    channel_id = row['ChannelID']\n",
    "    categoria = row['Categoría']\n",
    "    nombre_noticiero = row['Nombre del noticiero']\n",
    "    \n",
    "    if pd.notnull(channel_id):\n",
    "        for _, clave_row in claves.iterrows():\n",
    "            query = clave_row['Query']\n",
    "            country = clave_row['País']\n",
    "            search_results = search_videos(channel_id, query, april_first, april_end)\n",
    "            for video in search_results:\n",
    "                if video:\n",
    "                    video[\"Nombre del noticiero\"] = nombre_noticiero\n",
    "                    video[\"Query\"] = query  # Agregar la consulta a los datos del video\n",
    "                    if categoria == \"Internacional\":\n",
    "                        video[\"País\"] = f\"Internacional + {country}\"\n",
    "                    else:\n",
    "                        video[\"País\"] = categoria\n",
    "                    videos.append(video)\n",
    "\n",
    "# Crear DataFrame y guardar en CSV\n",
    "df_videos = pd.DataFrame(videos)\n",
    "df_videos.to_csv(\"./videos-per-month/abril.csv\", index=False)\n",
    "\n",
    "print(\"Videos data saved to ./videos-per-month/abril.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos[\"Numero de Comentarios\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de datos de Mayo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now()\n",
    "may_first = datetime(current_date.year, 5, 1).isoformat(\"T\") + \"Z\"\n",
    "may_end = datetime(current_date.year, 5, 31, 23, 59, 59).isoformat(\"T\") + \"Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se vuelve a correr la consulta de el mes de enero con las fechas modificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "for _, row in noticias.iterrows():\n",
    "    channel_id = row['ChannelID']\n",
    "    categoria = row['Categoría']\n",
    "    nombre_noticiero = row['Nombre del noticiero']\n",
    "    \n",
    "    if pd.notnull(channel_id):\n",
    "        for _, clave_row in claves.iterrows():\n",
    "            query = clave_row['Query']\n",
    "            country = clave_row['País']\n",
    "            search_results = search_videos(channel_id, query, may_first, may_end)\n",
    "            for video in search_results:\n",
    "                if video:\n",
    "                    video[\"Nombre del noticiero\"] = nombre_noticiero\n",
    "                    video[\"Query\"] = query  # Agregar la consulta a los datos del video\n",
    "                    if categoria == \"Internacional\":\n",
    "                        video[\"País\"] = f\"Internacional + {country}\"\n",
    "                    else:\n",
    "                        video[\"País\"] = categoria\n",
    "                    videos.append(video)\n",
    "\n",
    "# Crear DataFrame y guardar en CSV\n",
    "df_videos = pd.DataFrame(videos)\n",
    "df_videos.to_csv(\"./videos-per-month/mayo2.csv\", index=False)\n",
    "\n",
    "print(\"Videos data saved to ./videos-per-month/mayo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos[\"Numero de Comentarios\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de datos de Junio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now()\n",
    "june_first = datetime(current_date.year, 6, 1).isoformat(\"T\") + \"Z\"\n",
    "june_end = datetime(current_date.year, 6, 30, 23, 59, 59).isoformat(\"T\") + \"Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se vuelve a correr la consulta de el mes de enero con las fechas modificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "for _, row in noticias.iterrows():\n",
    "    channel_id = row['ChannelID']\n",
    "    categoria = row['Categoría']\n",
    "    nombre_noticiero = row['Nombre del noticiero']\n",
    "    \n",
    "    if pd.notnull(channel_id):\n",
    "        for _, clave_row in claves.iterrows():\n",
    "            query = clave_row['Query']\n",
    "            country = clave_row['País']\n",
    "            search_results = search_videos(channel_id, query, june_first, june_end)\n",
    "            for video in search_results:\n",
    "                if video:\n",
    "                    video[\"Nombre del noticiero\"] = nombre_noticiero\n",
    "                    video[\"Query\"] = query  # Agregar la consulta a los datos del video\n",
    "                    if categoria == \"Internacional\":\n",
    "                        video[\"País\"] = f\"Internacional + {country}\"\n",
    "                    else:\n",
    "                        video[\"País\"] = categoria\n",
    "                    videos.append(video)\n",
    "\n",
    "# Crear DataFrame y guardar en CSV\n",
    "df_videos = pd.DataFrame(videos)\n",
    "df_videos.to_csv(\"./videos-per-month/junio.csv\", index=False)\n",
    "\n",
    "print(\"Videos data saved to ./videos-per-month/junio.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "junio = pd.rea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junio = pd.read_csv(\"videos-per-month/junio.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juniocomments = junio[\"Numero de Comentarios\"].sum()\n",
    "\n",
    "juniocomments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar el número de comentarios de todos los videos\n",
    "# leer los archivos csv\n",
    "enero = pd.read_csv(\"./videos-per-month/enero.csv\")\n",
    "febrero = pd.read_csv(\"./videos-per-month/febrero.csv\")\n",
    "marzo = pd.read_csv(\"./videos-per-month/marzo.csv\")\n",
    "abril = pd.read_csv(\"./videos-per-month/abril.csv\")\n",
    "mayo = pd.read_csv(\"./videos-per-month/mayo.csv\")\n",
    "junio = pd.read_csv(\"videos-per-month/junio.csv\")\n",
    "\n",
    "# Concatenar los DataFrames\n",
    "anual = pd.concat([enero, febrero, marzo, abril, mayo, junio])\n",
    "\n",
    "# sumar el número de comentarios\n",
    "total_comments = anual[\"Numero de Comentarios\"].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se une en un solo dataset todos los meses extraidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo = anual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo[\"Numero de Comentarios\"].sum() # completo = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necesito la grfica segmentada por pais\n",
    "\n",
    "# Crear una columna para diferenciar entre Internacional y Nacional\n",
    "\n",
    "completo['Tipo'] = completo['País'].apply(lambda x: 'Internacional' if 'Internacional' in x else 'Nacional')\n",
    "\n",
    "# Agrupar los datos por 'País' y 'Tipo', sumando el número de comentarios\n",
    "grouped_data = completo.groupby(['País', 'Tipo'])['Numero de Comentarios'].sum().unstack().fillna(0).reset_index()\n",
    "\n",
    "# Crear la gráfica de barras apiladas\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Internacional', x=grouped_data['País'], y=grouped_data['Internacional'], marker_color='blue'),\n",
    "    go.Bar(name='Nacional', x=grouped_data['País'], y=grouped_data['Nacional'], marker_color='red')\n",
    "])\n",
    "\n",
    "# Cambiar el diseño de la gráfica para apilar las barras\n",
    "\n",
    "fig.update_layout(barmode='stack', title='Comparación del Número de Comentarios por País',\n",
    "                    xaxis_title='País', yaxis_title='Número de Comentarios')\n",
    "\n",
    "# Mostrar la\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo.to_csv(\"completo.csv\", index=False) # se renomnro a com_anuales para evitar confusiones con el nombre del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo[\"Numero de Comentarios\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificando Duplicados y presidentes relacionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales = pd.read_csv(\"./com_anuales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales[\"Numero de Comentarios\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar duplicados\n",
    "\n",
    "com_anuales[com_anuales.duplicated(subset=\"Link del Video\", keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar filas con el mismo link en general Y NOMBRE para identificar si son duplicados o no\n",
    "\n",
    "com_anuales[com_anuales.duplicated(subset=\"Link del Video\", keep=False) & com_anuales.duplicated(subset=\"Nombre del Video\", keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop completos con el mismo link \n",
    "com_anuales = com_anuales.drop_duplicates(subset=['Link del Video'])\n",
    "\n",
    "com_anuales[\"Numero de Comentarios\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales.to_csv(\"com_anuales_nd.csv\", index=False) # se almacena el archivo sin duplicados eb com_anuales_nd para la extraccion de comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar la distribucion de comentarios de com_anuales en el tiempo\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "com_anuales[\"Fecha del Video\"] = pd.to_datetime(com_anuales[\"Fecha del Video\"])\n",
    "\n",
    "fig = px.histogram(com_anuales, x=\"Fecha del Video\", title=\"Distribución de Fechas de Videos en com_anuales\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quitar la palabra internacional y el simbolo + de los valores de la columna pais para estructurar la informacion de manera correcta\n",
    "\n",
    "com_anuales[\"País\"] = com_anuales[\"País\"].str.replace(\"Internacional\", \"\").str.replace(\"+\", \"\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales[\"País\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales.groupby([\"Tipo\", \"País\"])[\"Numero de Comentarios\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales[\"Numero de Comentarios\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales['ID del Video'] = com_anuales['Link del Video'].apply(lambda x: x.split('v=')[-1]) # se obtiene el ID del video de la URL de cada video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_anuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your_api_key\"\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(video_id):\n",
    "    comments_data = []\n",
    "    request = youtube.commentThreads().list(\n",
    "        part='snippet,replies', # se obtienen los metadatos de los comentarios\n",
    "        videoId=video_id, # se especifica el ID del video\n",
    "        maxResults=100 # se obtienen 100 comentarios por solicitud\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    while request is not None: # se recorren los comentarios de los videos y sus respuestas asociadas si las hay \n",
    "        for item in response['items']: # procesamiento de comentarios princiaples\n",
    "            comment = item['snippet']['topLevelComment']['snippet'] # se extrae la información del comentario\n",
    "            comment_data = {\n",
    "                'video_id': video_id, # se almacen el ID del video\n",
    "                'comment_id': item['id'], # se almacen el ID del comentario\n",
    "                'text': comment['textDisplay'], # se almacena el texto del comentario\n",
    "                'likes': comment['likeCount'], # se almacena el número de likes del comentario\n",
    "                'type': 'principal' # se almacena el tipo de comentario\n",
    "            }\n",
    "            comments_data.append(comment_data)\n",
    "            \n",
    "            if 'replies' in item: # procesamiento de respuestas a comentarios\n",
    "                for reply in item['replies']['comments']: # se recorren las respuestas a los comentarios\n",
    "                    reply_data = {\n",
    "                        'video_id': video_id, # se almacena el ID del video\n",
    "                        'comment_id': reply['id'], # se almacena el ID del comentario\n",
    "                        'text': reply['snippet']['textDisplay'], # se almacena el texto del comentario\n",
    "                        'likes': reply['snippet']['likeCount'], # se almacena el número de likes del comentario\n",
    "                        'type': 'reply' # se almacen el tipo de comentario\n",
    "                    }\n",
    "                    comments_data.append(reply_data)\n",
    "        \n",
    "        if 'nextPageToken' in response: # como los comentarios pueden ser muchos, se hace paginacion, para obtener los siguientes comentarios se usa el token de la siguiente pagina\n",
    "            request = youtube.commentThreads().list( # se realiza la solicitud para obtener los siguientes comentarios\n",
    "                part='snippet,replies', # se obtienen los metadatos de los comentarios\n",
    "                videoId=video_id, # se especifica el ID del video\n",
    "                pageToken=response['nextPageToken'], # se especifica el token de la siguiente página de comentarios a obtener \n",
    "                maxResults=100 # se obtienen 100 comentarios por solicitud\n",
    "            )\n",
    "            response = request.execute()\n",
    "        else:\n",
    "            request = None\n",
    "    return comments_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_df = pd.DataFrame(columns=['video_id', 'comment_id', 'text', 'likes', 'type']) # se crea un DataFrame vacío para almacenar los comentarios\n",
    "\n",
    "# Iterar sobre cada ID de video y extraer los comentarios\n",
    "for video_id in com_anuales['ID del Video']: # se recorren los IDs de los videos\n",
    "    comments = get_video_comments(video_id) # se obtienen los comentarios del video\n",
    "    video_comments_df = pd.DataFrame(comments) # se crea un DataFrame con los comentarios del video\n",
    "    all_comments_df = pd.concat([all_comments_df, video_comments_df], ignore_index=True) # se concatenan los comentarios del video al DataFrame principal de comentarios\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "all_comments_df.to_csv('comentarios_yt', index=False) # se almacenan los comentarios en un archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comentarios = pd.read_csv(\"./data/complete/comentarios_videos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comentarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
